{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Repository Data from WebScrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github link>>\n",
    "https://github.com/topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is related with projects posted on different different topics on GITHUB.\n",
    "We will take each topic from github.\n",
    "From each topic we find USERNAME,PROJECTNAME,# of STARS,# of Watches Project links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using REQUEST lib of python to download data from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing request library\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_obj=requests.get('https://github.com/topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_obj.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 means ....request is succesfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TYPES OF STATUS_CODE.....................\n",
    "Informational responses (100–199)............\n",
    "Successful responses (200–299).............\n",
    "Redirection messages (300–399)...........\n",
    "Client error responses (400–499)............\n",
    "Server error responses (500–599)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response_obj.text    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will contain all data in text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content=response_obj.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_content[0:2000])\n",
    "# it is in html format...so lets save it in html format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Pages with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=BeautifulSoup(page_content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tags=doc.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"f4 color-fg-muted col-md-6 mx-auto\">Browse popular topics on GitHub.</p>,\n",
       " <p class=\"f3 lh-condensed text-center Link--primary mb-0 mt-1\">\n",
       "         Google\n",
       "       </p>,\n",
       " <p class=\"f5 color-fg-muted text-center mb-0 mt-1\">Google LLC is an American multinational technology company that specializes in Internet-related services and products.</p>,\n",
       " <p class=\"f3 lh-condensed text-center Link--primary mb-0 mt-1\">\n",
       "         Vagrant\n",
       "       </p>,\n",
       " <p class=\"f5 color-fg-muted text-center mb-0 mt-1\">Vagrant is an open-source software product for building and maintaining portable virtual software development environments.</p>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title_tags=doc.find_all('p',{'class':\"f3 lh-condensed mb-0 mt-1 Link--primary\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_discription_tags=doc.find_all('p',{'class':\"f5 color-fg-muted mb-0 mt-1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url_tags=doc.find_all('a',{'class':\"d-flex no-underline\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/topics/3d'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_url_tags[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7965ec90641c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtpoic_link1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://github.com/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtopic_link\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'topic_link' is not defined"
     ]
    }
   ],
   "source": [
    "tpoic_link1=\"https://github.com/\"+topic_link[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tpoic_link1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title=[]\n",
    "for tag in topic_title_tags:\n",
    "    topic_title.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_discription=[]\n",
    "for tag in topic_discription_tags:\n",
    "    topic_discription.append(tag.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url=[]\n",
    "base_url=\"https://github.com\"\n",
    "for tag in topic_url_tags:\n",
    "    topic_url.append(base_url+tag['href'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting Lists into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function who will take URL of github topics and return data frame containg all topics posted (on github) , theirs URLs, & discription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url=\"https://github.com\"\n",
    "topic_title=[]\n",
    "topic_discription=[]\n",
    "topic_url=[]\n",
    "\n",
    "def get_github_topics(github_topic_url):\n",
    "    response_obj=requests.get(github_topic_url)\n",
    "    page_content=response_obj.text\n",
    "    doc=BeautifulSoup(page_content,'html.parser')\n",
    "    \n",
    "    topic_title_tags=doc.find_all('p',{'class':\"f3 lh-condensed mb-0 mt-1 Link--primary\"})\n",
    "    topic_discription_tags=doc.find_all('p',{'class':\"f5 color-fg-muted mb-0 mt-1\"})\n",
    "    topic_url_tags=doc.find_all('a',{'class':\"d-flex no-underline\"})\n",
    "    \n",
    "    \n",
    "    for tag in topic_title_tags:\n",
    "        topic_title.append(tag.text)\n",
    "    \n",
    "    for tag in topic_discription_tags:\n",
    "        topic_discription.append(tag.text.strip())\n",
    "    \n",
    "    for tag in topic_url_tags:\n",
    "        topic_url.append(base_url+tag['href'].strip()) \n",
    "        \n",
    "    return pd.DataFrame(list(zip(topic_title, topic_discription, topic_url)),\n",
    "              columns=['Title','Discription', 'URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_details_df=get_github_topics('https://github.com/topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DATAs to CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('./WebData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_details_df.to_csv('./WebData/topicsdata.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping another PAGE form given URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(topic_url[0]).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_doc=BeautifulSoup(response,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags=page_doc.find_all('h3',{'class':\"f3 color-fg-muted text-normal lh-condensed\"})\n",
    "star_tags=page_doc.find_all('div',{'class':\"d-flex flex-items-start ml-3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name=[]\n",
    "repository_name=[]\n",
    "repository_url=[]\n",
    "for tag in name_tags:\n",
    "    user_name.append(tag.find_all('a')[0].text.strip())\n",
    "    repository_name.append(tag.find_all('a')[1].text.strip())\n",
    "    repository_url.append(\"https://github.com\" + tag.find_all('a')[1]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_stars=[]\n",
    "for tag in star_tags:\n",
    "    no_of_stars.append(float(tag.find_all('a')[-1].text.strip()[:-1])*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_df=pd.DataFrame(list(zip(user_name,repository_name,no_of_stars,repository_url)),\n",
    "                     columns=['user_name','repository_name','no_of_stars','repository_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting above things in one function to get info about a particular topic like....3D,ajax..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_info(topic_url):\n",
    "    response=requests.get(topic_url)\n",
    "    \n",
    "    if response.status_code !=200:\n",
    "        raise Exception('falied to load {}'.format(topic_url))\n",
    "        \n",
    "    page_doc=BeautifulSoup(response.text,'html.parser')\n",
    "    name_tags=page_doc.find_all('h3',{'class':\"f3 color-fg-muted text-normal lh-condensed\"})\n",
    "    star_tags=page_doc.find_all('div',{'class':\"d-flex flex-items-start ml-3\"})\n",
    "    user_name=[]\n",
    "    repository_name=[]\n",
    "    repository_url=[]\n",
    "    for tag in name_tags:\n",
    "        user_name.append(tag.find_all('a')[0].text.strip())\n",
    "        repository_name.append(tag.find_all('a')[1].text.strip())\n",
    "        repository_url.append(\"https://github.com\" + tag.find_all('a')[1]['href'])\n",
    "    no_of_stars=[]\n",
    "    for tag in star_tags:\n",
    "        no_of_stars.append(float(tag.find_all('a')[-1].text.strip()[:-1])*1000)\n",
    "    return pd.DataFrame(list(zip(user_name,repository_name,no_of_stars,repository_url)),\n",
    "                     columns=['user_name','repository_name','no_of_stars','repository_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating CSV file of all topics having infomation of USER_NAME, REPOSITORY_NAME, NO_OF_STARS, REPOSITORY_URL...  in WebData folder of current working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "falied to load https://github.com/topics/chrome",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-352f0a13949d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpath_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./WebData/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdata_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_topic_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'URL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-1d9978e64eff>\u001b[0m in \u001b[0;36mget_topic_info\u001b[1;34m(topic_url)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'falied to load {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpage_doc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: falied to load https://github.com/topics/chrome"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for index,row in topics_df.iterrows():\n",
    "    path_name='./WebData/'+row['Title']+'.csv'\n",
    "    if not os.path.exists(fname):\n",
    "        data_df=get_topic_info(row['URL'])\n",
    "        data_df.to_csv(path_name,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tools Used: Python,os, requests,pandas,BeautifulSoup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
